# Copyright (c) 2025 Parth Sinha and Shine Gupta. All rights reserved.
# DevFlowFix - Autonomous AI agent the detects, analyzes, and resolves CI/CD failures in real-time.

"""
Automated PR Creator Service

Creates and tracks automated fix pull requests in source repositories.
Uses per-repository GitHub tokens for secure access.
"""

from typing import Dict, Any, Optional, List
from datetime import datetime, timezone
from uuid import uuid4
import structlog

from app.core.models.incident import Incident
from app.core.models.analysis import AnalysisResult
from app.adapters.external.github.client import GitHubClient
from app.adapters.database.postgres.models import (
    PullRequestTable,
    PRCreationLogTable,
    PRStatus,
)
from app.services.github_token_manager import GitHubTokenManager
from app.core.enums import FailureType

logger = structlog.get_logger(__name__)

class PRCreatorService:
    """
    Service for creating automated fix pull requests.

    Creates PRs in source repositories with:
    - Code changes from NVIDIA AI analysis
    - Configuration updates
    - Detailed explanations
    - Prevention measures

    Features:
    - Per-repository GitHub token support
    - PR metadata tracking in database
    - Creation audit logging
    - Automatic branch management

    Example:
        ```python
        service = PRCreatorService()
        
        pr_result = await service.create_fix_pr(
            incident=incident,
            analysis=analysis,
            solution=solution,
        )
        
        print(f"PR created: {pr_result['pr_url']}")
        ```
    """
    def __init__(self, github_client: Optional[GitHubClient] = None):
        """
        Initialize PR creator service.
        
        Args:
            github_client: GitHub API client (optional, uses token manager)
        """
        self.github = github_client
        self.token_manager = GitHubTokenManager()
        self._db_session = None

    async def create_fix_pr(
            self,
            incident: Incident,
            analysis: AnalysisResult,
            solution: Dict[str, Any],
            user_id: Optional[str] = None,
            db_session=None,
    ) -> Dict[str, Any]:
        """
        Create an automated fix PR in the source repository.

        Args:
            incident: Incident details with repo information
            analysis: AI analysis result with root cause and fixability
            solution: NVIDIA AI-generated solution with code changes
            user_id: User ID for token retrieval (required)
            db_session: Database session for tracking

        Returns:
            PR result with metadata

        Raises:
            ValueError: If repository information or user_id not found
        """
        from app.dependencies import get_db

        # Get user_id from incident context if not provided
        if not user_id:
            user_id = incident.context.get("user_id")

        if not user_id:
            raise ValueError(
                "Cannot create PR: user_id required. "
                "Ensure the webhook includes user_id in the incident context."
            )

        repo_info = self._extract_repo_info(incident)
        if not repo_info:
            raise ValueError("Cannot create PR: repository info not found")

        owner = repo_info["owner"]
        repo = repo_info["repo"]
        base_branch = repo_info.get("branch", "main")

        # Get repo-specific GitHub token for THIS USER
        token = self.token_manager.get_token(user_id, owner, repo)
        if not token:
            raise ValueError(
                f"No GitHub token found for user {user_id} and repository {owner}/{repo}. "
                "Please register your token via /api/v1/pr-management/tokens/register"
            )
        
        # Create authenticated GitHub client for this repo
        github_client = GitHubClient(token=token)

        logger.info(
            "pr_creation_start",
            incident_id=incident.incident_id,
            owner=owner,
            repo=repo,
            failure_type=analysis.category.value,
            confidence=analysis.confidence,
        )

        creation_log_id = f"log_{uuid4()}"
        start_time = datetime.now(timezone.utc)
        
        try:
            branch_name = self._generate_branch_name(incident, analysis)
            await self._create_branch(
                github_client, owner, repo, base_branch, branch_name
            )

            changed_files = await self._apply_code_changes(
                github_client=github_client,
                owner=owner,
                repo=repo,
                branch=branch_name,
                code_changes=solution.get("code_changes", []),
            )

            config_files = await self._apply_config_changes(
                github_client=github_client,
                owner=owner,
                repo=repo,
                branch=branch_name,
                config_changes=solution.get("configuration_changes", []),
            )

            pr_title = self._generate_pr_title(analysis)
            pr_body = self._generate_pr_body(
                incident=incident,
                analysis=analysis,
                solution=solution,
                changed_files=changed_files + config_files,
            )

            pr_result = await github_client.create_pull_request(
                owner=owner,
                repo=repo,
                title=pr_title,
                body=pr_body,
                head=branch_name,
                base=base_branch,
            )

            # Store PR metadata in database
            db = db_session or next(get_db())
            
            pr_id = f"pr_{uuid4()}"
            
            pr_record = PullRequestTable(
                id=pr_id,
                incident_id=incident.incident_id,
                repository_owner=owner,
                repository_name=repo,
                repository_full=f"{owner}/{repo}",
                pr_number=pr_result["number"],
                pr_url=pr_result["html_url"],
                branch_name=branch_name,
                base_branch=base_branch,
                title=pr_title,
                description=pr_body,
                status=PRStatus.CREATED,
                files_changed=len(changed_files + config_files),
                failure_type=analysis.category.value if analysis.category else "unknown",
                root_cause=analysis.root_cause,
                confidence_score=analysis.confidence,
                metadata={
                    "incident_id": incident.incident_id,
                    "created_by": "devflowfix",
                    "version": "1.0",
                },
            )
            
            db.add(pr_record)
            
            # Log creation attempt
            creation_log = PRCreationLogTable(
                id=creation_log_id,
                incident_id=incident.incident_id,
                pr_id=pr_id,
                repository_full=f"{owner}/{repo}",
                branch_name=branch_name,
                failure_type=analysis.category.value if analysis.category else "unknown",
                root_cause=analysis.root_cause,
                files_to_change=len(changed_files + config_files),
                status="success",
                duration_ms=int(
                    (datetime.now(timezone.utc) - start_time).total_seconds() * 1000
                ),
                pr_url=pr_result["html_url"],
            )
            
            db.add(creation_log)
            db.commit()

            logger.info(
                "pr_created_success",
                incident_id=incident.incident_id,
                pr_id=pr_id,
                pr_number=pr_result["number"],
                pr_url=pr_result["html_url"],
                files_changed=len(changed_files + config_files),
            )

            return {
                **pr_result,
                "pr_id": pr_id,
                "files_changed": changed_files + config_files,
                "timestamp": start_time.isoformat(),
            }
            
        except Exception as e:
            logger.error(
                "pr_creation_failed",
                incident_id=incident.incident_id,
                owner=owner,
                repo=repo,
                error=str(e),
                exc_info=True,
            )
            
            # Log failed attempt
            try:
                db = db_session or next(get_db())
                
                creation_log = PRCreationLogTable(
                    id=creation_log_id,
                    incident_id=incident.incident_id,
                    pr_id=None,
                    repository_full=f"{owner}/{repo}",
                    branch_name=self._generate_branch_name(incident, analysis),
                    failure_type=analysis.category.value if analysis.category else "unknown",
                    root_cause=analysis.root_cause,
                    files_to_change=len(solution.get("code_changes", [])),
                    status="failed",
                    duration_ms=int(
                        (datetime.now(timezone.utc) - start_time).total_seconds() * 1000
                    ),
                    error_message=str(e),
                    error_type=type(e).__name__,
                )
                
                db.add(creation_log)
                db.commit()
            except Exception as log_error:
                logger.error("failed_to_log_pr_creation_error", error=str(log_error))
            
            raise
    
    def _extract_repo_info(self, incident: Incident) -> Optional[Dict[str, str]]:
        """Extract owner/repo from incident context."""
        repo_full = incident.context.get("repository")
        if not repo_full:
            return None
        
        parts = repo_full.split("/")
        if len(parts) != 2:
            return None
        
        return {
            "owner": parts[0],
            "repo": parts[1],
            "branch": incident.context.get("branch", "main"),
        }
    
    def _generate_branch_name(
            self,
            incident: Incident,
            analysis: AnalysisResult,
    ) -> str:
        """Generate branch name for the fix."""
        failure_type = analysis.category.value.replace("_", "-")
        incident_id = incident.incident_id[:8]
        return f"devflowfix/auto-fix-{failure_type}-{incident_id}"
    
    async def _create_branch(
            self,
            github_client: GitHubClient,
            owner: str,
            repo: str,
            base_branch: str,
            new_branch: str,
    ):
        """Create new branch from base."""
        base_ref = await github_client.get_ref(owner, repo, f"heads/{base_branch}")
        base_sha = base_ref["object"]["sha"]

        await github_client.create_ref(
            owner=owner,
            repo=repo,
            ref=f"refs/heads/{new_branch}",
            sha=base_sha,
        )

        logger.info(
            "branch_created",
            owner=owner,
            repo=repo,
            branch=new_branch
        )

    async def _apply_code_changes(
            self,
            github_client: GitHubClient,
            owner: str,
            repo: str,
            branch: str,
            code_changes: List[Dict[str, Any]],
    ) -> List[str]:
        """Apply code changes to files."""
        changed_files = []

        for change in code_changes:
            file_path = change.get("file_path")
            fixed_code = change.get("fixed_code")
            
            if not file_path or not fixed_code:
                continue

            try:
                try:
                    current_file = await github_client.get_file_contents(
                        owner=owner,
                        repo=repo,
                        path=file_path,
                        ref=branch,
                    )
                    sha = current_file["sha"]
                except:
                    sha = None

                await github_client.create_or_update_file(
                    owner=owner,
                    repo=repo,
                    path=file_path,
                    message=f"fix: {change.get('explanation', 'Auto-fix code issue')}",
                    content=fixed_code,
                    branch=branch,
                    sha=sha,
                )

                changed_files.append(file_path)

                logger.info(
                    "code_change_applied",
                    owner=owner,
                    repo=repo,
                    file=file_path,
                )

            except Exception as e:
                logger.error(
                    "code_change_failed",
                    file=file_path,
                    error=str(e),
                )
        return changed_files
    
    async def _apply_config_changes(
            self,
            github_client: GitHubClient,
            owner: str,
            repo: str,
            branch: str,
            config_changes: List[Dict[str, Any]],       
    ) -> List[str]:
        """Apply configuration changes."""
        changed_files = []

        for change in config_changes:
            file_path = change.get("file")
            
            if not file_path:
                continue
            
            try:
                try:
                    current_file = await github_client.get_file_contents(
                        owner=owner,
                        repo=repo,
                        path=file_path,
                        ref=branch,
                    )
                    sha = current_file["sha"]
                except:
                    sha = None
                
                # Use recommended value for config
                new_value = change.get("recommended_value", change.get("value", ""))
                
                config_content = f"{change.get('setting', 'config')}: {new_value}\n"
                
                await github_client.create_or_update_file(
                    owner=owner,
                    repo=repo,
                    path=file_path,
                    message=f"config: {change.get('reason', 'Update configuration')}",
                    content=config_content,
                    branch=branch,
                    sha=sha,
                )
                
                changed_files.append(file_path)
                
                logger.info(
                    "config_change_applied",
                    owner=owner,
                    repo=repo,
                    file=file_path,
                    setting=change.get('setting'),
                )
                
            except Exception as e:
                logger.error(
                    "config_change_failed",
                    file=file_path,
                    error=str(e),
                )
        
        return changed_files


    def _generate_pr_title(self, analysis: AnalysisResult) -> str:
        """Generate PR title."""
        failure_type = analysis.category.value.replace("_", " ").title()
        return f"DevFlowFix: {failure_type}"
    
    def _generate_pr_body(
        self,
        incident: Incident,
        analysis: AnalysisResult,
        solution: Dict[str, Any],
        changed_files: List[str],
    ) -> str:
        """Generate detailed PR description."""
        immediate_fix = solution.get("immediate_fix", {})
        code_changes = solution.get("code_changes", [])
        prevention = solution.get("prevention_measures", [])
        
        body = f"""## ðŸ¤– Automated Fix by DevFlowFix

### Problem Detected
- **Failure Type**: {analysis.category.value.replace("_", " ").title()}
- **Root Cause**: {analysis.root_cause}
- **Confidence**: {analysis.confidence:.0%}
- **Incident ID**: `{incident.incident_id}`

### Changes Made

"""
        
        # List changed files
        if changed_files:
            body += "**Modified Files:**\n"
            for file in changed_files:
                body += f"- `{file}`\n"
            body += "\n"
        
        # Immediate fix description
        if immediate_fix:
            body += f"""### Fix Description

{immediate_fix.get('description', '')}

**Estimated Time**: {immediate_fix.get('estimated_time_minutes', 0)} minutes
**Risk Level**: {immediate_fix.get('risk_level', 'Unknown').upper()}

**Steps Taken**:
"""
            for i, step in enumerate(immediate_fix.get('steps', []), 1):
                body += f"{i}. {step}\n"
            body += "\n"
        
        # Code changes detail
        if code_changes:
            body += "### Code Changes\n\n"
            for idx, change in enumerate(code_changes, 1):
                body += f"**{idx}. {change.get('file_path', 'N/A')}**\n"
                body += f"- Line(s): {change.get('line_numbers', 'N/A')}\n"
                body += f"- Explanation: {change.get('explanation', 'N/A')}\n\n"
        
        # Prevention measures
        if prevention:
            body += "### Prevention Measures\n\n"
            body += "To prevent similar issues in the future:\n\n"
            for measure in prevention[:3]:
                body += f"- **{measure.get('measure', '')}**: "
                body += f"{measure.get('description', '')}\n"
            body += "\n"
        
        # Footer
        body += """---

*This PR was automatically generated by DevFlowFix AI. Please review the changes before merging.*

**Review Checklist**:
- [ ] Changes address the root cause
- [ ] No unintended side effects
- [ ] Tests pass
- [ ] Documentation updated (if needed)
"""
        
        return body
    
    def should_create_pr(
        self,
        analysis: AnalysisResult,
        incident: Incident,
        min_confidence: float = 0.85,
    ) -> bool:
        """
        Determine if PR should be created.
        
        Args:
            analysis: Analysis result
            incident: Incident details
            min_confidence: Minimum confidence threshold
            
        Returns:
            True if PR should be created
        """
        # Check confidence
        if analysis.confidence < min_confidence:
            logger.info(
                "pr_skipped_low_confidence",
                incident_id=incident.incident_id,
                confidence=analysis.confidence,
            )
            return False
        
        # Only create PRs for certain failure types
        auto_fix_types = [
            FailureType.LINT_FAILURE,
            FailureType.TEST_FAILURE,
            FailureType.DEPENDENCY_ERROR,
            FailureType.CONFIG_ERROR,
        ]
        
        if analysis.category not in auto_fix_types:
            logger.info(
                "pr_skipped_failure_type",
                incident_id=incident.incident_id,
                failure_type=analysis.category.value,
            )
            return False
        
        # Check if repo info available
        if not incident.context.get("repository"):
            logger.info(
                "pr_skipped_no_repo",
                incident_id=incident.incident_id,
            )
            return False
        
        return True 