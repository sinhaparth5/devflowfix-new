# CodeHealer - Complete File Documentation
## Detailed Description of Every File and Its Purpose

---

## ðŸ“ Root Level Files

### **README.md**
**Purpose**: Project overview and getting started guide
**Contents**:
- What CodeHealer does (elevator pitch)
- Quick start instructions
- Architecture diagram
- Links to detailed documentation
- Badge links (build status, coverage, license)
**Why it exists**: First file people see when visiting your GitHub repo

### **LICENSE**
**Purpose**: Legal license for your code
**Contents**: MIT, Apache 2.0, or proprietary license text
**Why it exists**: Defines how others can use your code

### **CONTRIBUTING.md**
**Purpose**: Guidelines for contributing to the project
**Contents**:
- How to set up development environment
- Code style guidelines
- Pull request process
- How to report bugs
**Why it exists**: Makes it easy for others (or future you) to contribute

### **CHANGELOG.md**
**Purpose**: Record of all notable changes to the project
**Contents**:
- Version history (v1.0.0, v1.1.0, etc.)
- What changed in each version
- Breaking changes highlighted
**Format**: Keep a Changelog format
**Why it exists**: Users and developers can track what changed between versions

### **.gitignore**
**Purpose**: Tell Git which files to NOT track
**Contents**:
- `*.pyc` (Python bytecode)
- `.env` (secrets)
- `__pycache__/`
- `uv.lock` (or not, depending on preference)
- `.terraform/`
- `*.log`
**Why it exists**: Prevents committing secrets, build artifacts, local config

### **.env.example**
**Purpose**: Template for environment variables
**Contents**:
```bash
DATABASE_URL=postgresql://user:pass@localhost:5432/codehealer
NVIDIA_API_KEY=your_api_key_here
GITHUB_TOKEN=ghp_xxxxx
SLACK_TOKEN=xoxb-xxxxx
```
**Why it exists**: Shows developers what environment variables they need to set

### **.dockerignore**
**Purpose**: Tell Docker which files to NOT include in image builds
**Contents**:
- `.git/`
- `tests/`
- `*.md`
- `.env`
- `notebooks/`
**Why it exists**: Makes Docker images smaller and faster to build

### **pyproject.toml**
**Purpose**: Python project configuration for uv
**Contents**:
- Project metadata (name, version, description)
- Dependencies (fastapi, sqlmodel, httpx, etc.)
- Dev dependencies (pytest, ruff, mypy)
- Tool configurations (ruff, mypy, pytest settings)
**Example**:
```toml
[project]
name = "codehealer"
version = "0.1.0"
dependencies = [
    "fastapi>=0.104.0",
    "sqlmodel>=0.0.14",
    "httpx>=0.25.0",
]
```
**Why it exists**: Single source of truth for project configuration

### **uv.lock**
**Purpose**: Lock file for exact dependency versions
**Contents**: Auto-generated by uv with exact versions and hashes
**Why it exists**: Ensures everyone has the exact same dependency versions

### **.python-version**
**Purpose**: Specifies Python version for uv
**Contents**: `3.11` or `3.11.5`
**Why it exists**: Ensures consistent Python version across environments

### **Dockerfile.lambda**
**Purpose**: Docker image for AWS Lambda deployment
**Contents**:
- Base image: `public.ecr.aws/lambda/python:3.11`
- Copy application code
- Install dependencies with uv
- Set CMD to Lambda handler
**Why it exists**: Lambda requires container image for deployment

### **docker-compose.yml**
**Purpose**: Local development environment setup
**Contents**:
- PostgreSQL service with pgvector
- Redis service (optional)
- Your app service
- Port mappings
- Volume mounts
**Why it exists**: One command (`docker-compose up`) starts entire local stack

### **Makefile**
**Purpose**: Shortcuts for common development commands
**Contents**:
```makefile
.PHONY: install test lint deploy

install:
	uv sync

test:
	uv run pytest

lint:
	uv run ruff check .

deploy:
	./scripts/deploy_lambda.sh prod
```
**Why it exists**: `make test` is easier than remembering long commands

### **justfile**
**Purpose**: Alternative to Makefile (Rust-based, more modern)
**Contents**: Same as Makefile but with `just` syntax
**Why it exists**: Some developers prefer `just` over `make`

---

## ðŸ“ app/ - Main Application Code

### **app/__init__.py**
**Purpose**: Makes `app/` a Python package
**Contents**: Usually empty, or imports for convenience
**Why it exists**: Required for Python to treat directory as a package

### **app/main.py**
**Purpose**: FastAPI application initialization and configuration
**Contents**:
- Create FastAPI app instance
- Register all routers (webhook, incidents, health)
- Configure middleware (CORS, logging, error handling)
- Setup startup/shutdown events (database connections)
**Example**:
```python
from fastapi import FastAPI
from app.api.v1.router import api_router

app = FastAPI(title="CodeHealer", version="0.1.0")
app.include_router(api_router, prefix="/api/v1")

@app.on_event("startup")
async def startup():
    # Initialize database connection pool
    pass
```
**Why it exists**: Entry point for FastAPI application

### **app/lambda_handler.py**
**Purpose**: AWS Lambda entry point (wraps FastAPI)
**Contents**:
- Import FastAPI app from `main.py`
- Use Mangum to adapt FastAPI for Lambda
- Export `handler` function for Lambda
**Example**:
```python
from mangum import Mangum
from app.main import app

handler = Mangum(app, lifespan="off")
```
**Why it exists**: Lambda needs a `handler` function, not a ASGI server

### **app/dependencies.py**
**Purpose**: Dependency injection container
**Contents**:
- Database session factory
- Service instances (analyzer, remediator, etc.)
- Configuration loading
- Dependency functions for FastAPI routes
**Example**:
```python
from fastapi import Depends
from sqlmodel import Session

def get_db_session() -> Session:
    # Return database session
    pass

def get_analyzer_service(db: Session = Depends(get_db_session)):
    # Return analyzer service instance
    pass
```
**Why it exists**: Centralized place for creating and injecting dependencies

### **app/middleware.py**
**Purpose**: Custom FastAPI middleware
**Contents**:
- Request/response logging middleware
- Authentication middleware
- Error handling middleware
- Request ID generation
- Timing middleware (track request duration)
**Example**:
```python
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware

class LoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # Log request details
        response = await call_next(request)
        # Log response details
        return response
```
**Why it exists**: Cross-cutting concerns that apply to all requests

### **app/exceptions.py**
**Purpose**: Custom exception classes
**Contents**:
- `IncidentNotFoundError`
- `RemediationFailedError`
- `ConfidenceTooLowError`
- `RateLimitExceededError`
- Exception handlers (convert exceptions to HTTP responses)
**Example**:
```python
class IncidentNotFoundError(Exception):
    """Raised when incident doesn't exist in database"""
    pass

class ConfidenceTooLowError(Exception):
    """Raised when confidence score below threshold"""
    def __init__(self, confidence: float, threshold: float):
        self.confidence = confidence
        self.threshold = threshold
```
**Why it exists**: Type-safe error handling throughout application

---

## ðŸ“ app/api/ - API Layer (Controllers)

### **app/api/v1/router.py**
**Purpose**: Main v1 API router that combines all sub-routers
**Contents**:
- Import all endpoint routers (webhook, incidents, health)
- Create APIRouter instance
- Include all sub-routers
**Example**:
```python
from fastapi import APIRouter
from app.api.v1 import webhook, incidents, health

api_router = APIRouter()
api_router.include_router(webhook.router, prefix="/webhook", tags=["webhook"])
api_router.include_router(incidents.router, prefix="/incidents", tags=["incidents"])
api_router.include_router(health.router, prefix="/health", tags=["health"])
```
**Why it exists**: Single place to register all API endpoints

### **app/api/v1/webhook.py**
**Purpose**: Webhook endpoint for receiving events from GitHub/ArgoCD/K8s
**Contents**:
- `POST /webhook` endpoint
- Webhook signature verification (GitHub HMAC, ArgoCD token)
- Event normalization using EventFactory
- Queue event for processing or process synchronously
**Example**:
```python
@router.post("/webhook")
async def handle_webhook(
    request: Request,
    event_processor: EventProcessor = Depends(get_event_processor)
):
    # 1. Verify webhook signature
    # 2. Parse payload
    # 3. Create normalized event
    # 4. Process or queue event
    # 5. Return acknowledgment
    pass
```
**Why it exists**: Single endpoint to receive all CI/CD events

### **app/api/v1/incidents.py**
**Purpose**: CRUD endpoints for incident management
**Contents**:
- `GET /incidents` - List incidents (with pagination, filters)
- `GET /incidents/{id}` - Get single incident
- `POST /incidents` - Create incident manually (for testing)
- `PATCH /incidents/{id}` - Update incident
- `GET /incidents/analytics` - Aggregate statistics
**Example**:
```python
@router.get("/incidents", response_model=List[IncidentResponse])
async def list_incidents(
    skip: int = 0,
    limit: int = 100,
    source: Optional[str] = None,
    db: Session = Depends(get_db_session)
):
    # Query incidents from database with filters
    pass
```
**Why it exists**: API for viewing and managing incident history

### **app/api/v1/health.py**
**Purpose**: Health check and readiness endpoints
**Contents**:
- `GET /health` - Simple health check (200 OK)
- `GET /ready` - Readiness check (database connection, external APIs)
- `GET /metrics` - Prometheus metrics (optional)
**Example**:
```python
@router.get("/health")
async def health_check():
    return {"status": "healthy"}

@router.get("/ready")
async def readiness_check(db: Session = Depends(get_db_session)):
    # Check database connection
    # Check NVIDIA API reachable
    # Return 200 if all healthy, 503 if not
    pass
```
**Why it exists**: Load balancers and monitoring tools need health endpoints

### **app/api/v1/approvals.py**
**Purpose**: Human approval workflow endpoints
**Contents**:
- `POST /approvals` - Approve or reject a proposed remediation
- `GET /approvals/pending` - List pending approvals
- Slack interactive message callback handling
**Example**:
```python
@router.post("/approvals")
async def handle_approval(
    approval: ApprovalRequest,
    remediator: RemediatorService = Depends(get_remediator)
):
    # 1. Validate approval token
    # 2. Load incident
    # 3. Execute remediation if approved
    # 4. Update incident status
    # 5. Notify Slack
    pass
```
**Why it exists**: Allows humans to approve/reject auto-fix suggestions

### **app/api/v1/analytics.py**
**Purpose**: Analytics and dashboard data endpoints
**Contents**:
- `GET /analytics/dashboard` - Overall metrics (success rate, avg resolution time)
- `GET /analytics/confidence-distribution` - Confidence score distribution
- `GET /analytics/failure-types` - Most common failure types
- `GET /analytics/time-series` - Incidents over time
**Example**:
```python
@router.get("/analytics/dashboard")
async def get_dashboard_metrics(
    start_date: datetime,
    end_date: datetime,
    db: Session = Depends(get_db_session)
):
    # Query aggregated metrics from database
    # Return success rate, avg time, total incidents, etc.
    pass
```
**Why it exists**: Data for building monitoring dashboards

### **app/api/v1/admin.py**
**Purpose**: Admin-only operations
**Contents**:
- `POST /admin/replay/{incident_id}` - Replay incident processing
- `POST /admin/reprocess-embeddings` - Rebuild vector embeddings
- `POST /admin/calibrate-confidence` - Trigger confidence recalibration
- Authentication required for all endpoints
**Example**:
```python
@router.post("/admin/replay/{incident_id}")
async def replay_incident(
    incident_id: str,
    current_user: User = Depends(get_admin_user),
    event_processor: EventProcessor = Depends(get_event_processor)
):
    # Reload incident from database
    # Reprocess through pipeline
    # Return new analysis results
    pass
```
**Why it exists**: Operations tasks that shouldn't be in production code

### **app/api/dependencies.py**
**Purpose**: API-specific dependency injection functions
**Contents**:
- Authentication dependencies (`get_current_user`, `require_admin`)
- Rate limiting dependencies
- API-specific service factories
**Example**:
```python
async def get_current_user(token: str = Depends(oauth2_scheme)):
    # Validate JWT token
    # Return user object or raise 401
    pass

async def require_admin(user: User = Depends(get_current_user)):
    if not user.is_admin:
        raise HTTPException(status_code=403)
    return user
```
**Why it exists**: Keeps auth logic separate from business logic

---

## ðŸ“ app/core/ - Core Domain Layer

### **app/core/config.py**
**Purpose**: Application configuration using Pydantic Settings
**Contents**:
- Load environment variables
- Validate configuration
- Provide typed access to settings
- Different configs per environment (dev/staging/prod)
**Example**:
```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # Database
    database_url: str
    
    # APIs
    nvidia_api_key: str
    github_token: str
    slack_token: str
    
    # Application
    environment: str = "dev"
    log_level: str = "INFO"
    max_confidence_threshold: float = 0.95
    
    class Config:
        env_file = ".env"

settings = Settings()
```
**Why it exists**: Centralized, type-safe configuration management

### **app/core/constants.py**
**Purpose**: System-wide constants
**Contents**:
- `MAX_INCIDENTS_PER_HOUR = 10` (blast radius limit)
- `DEFAULT_CONFIDENCE_THRESHOLD = 0.85`
- `EMBEDDING_DIMENSION = 768`
- `SUPPORTED_EVENT_SOURCES = ["github", "argocd", "kubernetes"]`
**Why it exists**: Avoid magic numbers scattered throughout code

### **app/core/enums.py**
**Purpose**: Enumerations for domain concepts
**Contents**:
```python
from enum import Enum

class IncidentSource(str, Enum):
    GITHUB = "github"
    ARGOCD = "argocd"
    KUBERNETES = "kubernetes"

class Severity(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class Outcome(str, Enum):
    SUCCESS = "success"
    FAILED = "failed"
    PENDING = "pending"
    ESCALATED = "escalated"

class Fixability(str, Enum):
    AUTO = "auto"
    MANUAL = "manual"
    UNKNOWN = "unknown"
```
**Why it exists**: Type-safe enums prevent typos and invalid values

---

## ðŸ“ app/core/events/ - Event Models

### **app/core/events/base.py**
**Purpose**: Base event classes
**Contents**:
- `BaseEvent` - Abstract base class for all events
- `NormalizedEvent` - Standardized event format after normalization
**Example**:
```python
from pydantic import BaseModel
from datetime import datetime

class BaseEvent(BaseModel):
    """Base class for all events"""
    event_id: str
    timestamp: datetime
    source: IncidentSource

class NormalizedEvent(BaseModel):
    """Normalized event after processing raw webhook"""
    incident_id: str
    source: IncidentSource
    severity: Severity
    error_log: str
    context: dict  # repo, branch, commit, etc.
    raw_payload: dict  # Original webhook payload
```
**Why it exists**: Common interface for all events regardless of source

### **app/core/events/github.py**
**Purpose**: GitHub-specific event models
**Contents**:
- `GitHubWorkflowFailedEvent` - Workflow run failure
- `GitHubActionFailedEvent` - Individual action failure
- Pydantic models matching GitHub webhook payload structure
**Example**:
```python
class GitHubWorkflowFailedEvent(BaseEvent):
    repository: str
    workflow_name: str
    run_id: int
    commit_sha: str
    branch: str
    conclusion: str  # "failure", "timeout", etc.
    logs_url: str
```
**Why it exists**: Type-safe parsing of GitHub webhooks

### **app/core/events/argocd.py**
**Purpose**: ArgoCD-specific event models
**Contents**:
- `ArgoCDSyncFailedEvent` - Application sync failure
- `ArgoCDHealthDegradedEvent` - Health status degraded
**Example**:
```python
class ArgoCDSyncFailedEvent(BaseEvent):
    application_name: str
    namespace: str
    sync_status: str
    health_status: str
    error_message: str
    target_revision: str
```
**Why it exists**: Type-safe parsing of ArgoCD webhooks

### **app/core/events/kubernetes.py**
**Purpose**: Kubernetes-specific event models
**Contents**:
- `K8sPodCrashLoopEvent` - Pod in CrashLoopBackOff
- `K8sImagePullBackOffEvent` - Image pull failure
- `K8sOOMKilledEvent` - Out of memory kill
**Example**:
```python
class K8sPodCrashLoopEvent(BaseEvent):
    pod_name: str
    namespace: str
    container_name: str
    reason: str
    message: str
    restart_count: int
```
**Why it exists**: Type-safe parsing of K8s events

### **app/core/events/factory.py**
**Purpose**: Factory for creating event objects (Factory Pattern)
**Contents**:
- `EventFactory` class with `create()` method
- Logic to detect event source from webhook headers
- Parse raw payload into appropriate event model
**Example**:
```python
class EventFactory:
    @staticmethod
    def create(headers: dict, payload: dict) -> BaseEvent:
        # Detect source from headers
        if "X-GitHub-Event" in headers:
            return GitHubWorkflowFailedEvent(**payload)
        elif "X-ArgoCD-Event" in headers:
            return ArgoCDSyncFailedEvent(**payload)
        elif "X-Kubernetes-Event" in headers:
            return K8sPodCrashLoopEvent(**payload)
        else:
            raise ValueError("Unknown event source")
```
**Why it exists**: Single place to handle all webhook parsing logic

---

## ðŸ“ app/core/models/ - Domain Models

### **app/core/models/incident.py**
**Purpose**: Core Incident domain entity
**Contents**:
- `Incident` class representing a single incident
- Business logic methods (calculate_duration, is_resolved, etc.)
- Not a database model (that's in adapters/database)
**Example**:
```python
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Incident:
    incident_id: str
    timestamp: datetime
    source: IncidentSource
    severity: Severity
    error_log: str
    root_cause: Optional[str] = None
    confidence: Optional[float] = None
    outcome: Optional[Outcome] = None
    resolution_time_seconds: Optional[int] = None
    
    def is_resolved(self) -> bool:
        return self.outcome == Outcome.SUCCESS
    
    def calculate_duration(self) -> int:
        if self.resolution_time_seconds:
            return self.resolution_time_seconds
        return int((datetime.utcnow() - self.timestamp).total_seconds())
```
**Why it exists**: Domain model separate from database model (Clean Architecture)

### **app/core/models/analysis.py**
**Purpose**: Analysis result value object
**Contents**:
- `AnalysisResult` - Output from analyzer service
- Contains classification, root cause, fixability, confidence
**Example**:
```python
@dataclass
class AnalysisResult:
    category: str  # "imagepullbackoff", "oomkilled", etc.
    root_cause: str  # "Expired registry credentials"
    fixability: Fixability
    confidence: float  # 0.0 to 1.0
    similar_incidents: List[dict]  # From RAG retrieval
    reasoning: str  # LLM's explanation
```
**Why it exists**: Structured output from LLM analysis

### **app/core/models/remediation.py**
**Purpose**: Remediation plan and result models
**Contents**:
- `RemediationPlan` - What to do to fix the incident
- `RemediationResult` - What happened when we tried to fix it
**Example**:
```python
@dataclass
class RemediationPlan:
    action_type: str  # "github_rerun", "k8s_restart_pod", etc.
    parameters: dict  # Action-specific params
    estimated_duration_seconds: int
    risk_level: str  # "low", "medium", "high"

@dataclass
class RemediationResult:
    success: bool
    executed_at: datetime
    duration_seconds: int
    error_message: Optional[str] = None
    rollback_required: bool = False
```
**Why it exists**: Separate planning from execution

### **app/core/models/confidence.py**
**Purpose**: Confidence score value object
**Contents**:
- `ConfidenceScore` - Structured confidence breakdown
- Individual scores from different sources (LLM, similarity, historical)
**Example**:
```python
@dataclass
class ConfidenceScore:
    llm_confidence: float  # From LLM's own assessment
    similarity_score: float  # Cosine similarity to past incidents
    historical_success_rate: float  # Success rate for this fix type
    final_score: float  # Weighted combination
    
    @property
    def is_high_confidence(self) -> bool:
        return self.final_score >= 0.85
```
**Why it exists**: Transparency into how confidence is calculated

### **app/core/models/context.py**
**Purpose**: Execution context for remediation
**Contents**:
- `ExecutionContext` - Environment and constraints for executing fixes
- Repository info, cluster info, approval status
**Example**:
```python
@dataclass
class ExecutionContext:
    environment: str  # "dev", "staging", "prod"
    dry_run: bool  # If true, don't actually execute
    requires_approval: bool
    approval_timeout_minutes: int
    repository: Optional[str] = None
    cluster: Optional[str] = None
```
**Why it exists**: Pass context through remediation pipeline

---

## ðŸ“ app/core/schemas/ - Pydantic Schemas (API Contracts)

### **app/core/schemas/webhook.py**
**Purpose**: API schemas for webhook endpoint
**Contents**:
- `WebhookPayload` - Request body schema
- `WebhookResponse` - Response schema
**Example**:
```python
from pydantic import BaseModel

class WebhookPayload(BaseModel):
    # Generic webhook payload
    event_type: str
    data: dict

class WebhookResponse(BaseModel):
    incident_id: str
    acknowledged: bool
    queued: bool
```
**Why it exists**: API contract validation with Pydantic

### **app/core/schemas/incident.py**
**Purpose**: API schemas for incident endpoints
**Contents**:
- `IncidentCreate` - Request to create incident
- `IncidentResponse` - Incident in API response
- `IncidentUpdate` - Update incident fields
**Example**:
```python
class IncidentResponse(BaseModel):
    incident_id: str
    timestamp: datetime
    source: str
    severity: str
    error_log: str
    root_cause: Optional[str]
    confidence: Optional[float]
    outcome: Optional[str]
    
    class Config:
        from_attributes = True  # Allow ORM models
```
**Why it exists**: API response serialization

### **app/core/schemas/analysis.py**
**Purpose**: API schemas for analysis operations
**Contents**:
- `AnalysisRequest` - Request analysis manually
- `AnalysisResponse` - Analysis results
**Why it exists**: API contracts for analysis endpoints

### **app/core/schemas/approval.py**
**Purpose**: API schemas for approval workflow
**Contents**:
- `ApprovalRequest` - Approve or reject remediation
- `ApprovalResponse` - Approval result
**Example**:
```python
class ApprovalRequest(BaseModel):
    incident_id: str
    approved: bool
    approver: str
    comment: Optional[str]
```
**Why it exists**: API contract for approval flow

### **app/core/schemas/common.py**
**Purpose**: Common API schemas
**Contents**:
- `PaginationParams` - Pagination query params
- `FilterParams` - Common filters
- `ErrorResponse` - Standardized error response
**Example**:
```python
class PaginationParams(BaseModel):
    skip: int = 0
    limit: int = 100

class ErrorResponse(BaseModel):
    error: str
    detail: str
    timestamp: datetime
```
**Why it exists**: DRY - reusable across multiple endpoints

---

## ðŸ“ app/services/ - Application Services (Use Cases)

### **app/services/base.py**
**Purpose**: Base service class with common functionality
**Contents**:
- Base class all services inherit from
- Common utilities (logging, error handling)
**Example**:
```python
class BaseService:
    def __init__(self, logger: Logger):
        self.logger = logger
    
    def _log_operation(self, operation: str, **kwargs):
        self.logger.info(f"Operation: {operation}", extra=kwargs)
```
**Why it exists**: DRY - common service functionality

### **app/services/event_processor.py**
**Purpose**: Orchestrates the entire event processing pipeline
**Contents**:
- Main coordinator that calls all other services
- Steps: normalize â†’ analyze â†’ decide â†’ execute â†’ log
**Example**:
```python
class EventProcessor:
    def __init__(
        self,
        analyzer: AnalyzerService,
        decision: DecisionService,
        remediator: RemediatorService,
        incident_repo: IncidentRepository
    ):
        self.analyzer = analyzer
        self.decision = decision
        self.remediator = remediator
        self.incident_repo = incident_repo
    
    async def process(self, event: NormalizedEvent) -> Incident:
        # 1. Create incident record
        incident = self.incident_repo.create(event)
        
        # 2. Analyze the failure
        analysis = await self.analyzer.analyze(event)
        
        # 3. Decide: auto-fix or escalate?
        should_fix = self.decision.should_auto_fix(analysis)
        
        # 4. Execute remediation if approved
        if should_fix:
            result = await self.remediator.remediate(incident, analysis)
        else:
            # Escalate to human
            await self.escalate(incident, analysis)
        
        # 5. Update incident with results
        self.incident_repo.update(incident)
        
        return incident
```
**Why it exists**: Central orchestrator - implements the main business workflow

### **app/services/analyzer.py**
**Purpose**: LLM + RAG analysis of failures
**Contents**:
- Call NVIDIA API to classify failure
- Use embedder to get embedding
- Search vector DB for similar incidents
- Calculate confidence score
- Return AnalysisResult
**Example**:
```python
class AnalyzerService:
    def __init__(
        self,
        llm_client: NVIDIALLMClient,
        embedder: EmbedderService,
        vector_repo: VectorRepository
    ):
        self.llm = llm_client
        self.embedder = embedder
        self.vector_repo = vector_repo
    
    async def analyze(self, event: NormalizedEvent) -> AnalysisResult:
        # 1. Generate embedding
        embedding = await self.embedder.embed(event.error_log)
        
        # 2. Search for similar incidents
        similar = self.vector_repo.search(embedding, top_k=5)
        
        # 3. Build prompt with context
        prompt = self._build_prompt(event, similar)
        
        # 4. Call LLM
        llm_response = await self.llm.classify(prompt)
        
        # 5. Calculate confidence
        confidence = self._calculate_confidence(llm_response, similar)
        
        return AnalysisResult(
            category=llm_response["category"],
            root_cause=llm_response["root_cause"],
            fixability=llm_response["fixability"],
            confidence=confidence,
            similar_incidents=similar
        )
```
**Why it exists**: Core AI analysis logic

### **app/services/retriever.py**
**Purpose**: RAG retrieval from multiple sources
**Contents**:
- Search vector database for similar incidents
- Search Slack for related conversations
- Search documentation
- Rank and combine results
**Example**:
```python
class RetrieverService:
    async def retrieve_context(
        self,
        query_embedding: List[float],
        error_log: str
    ) -> dict:
        # 1. Vector search in database
        vector_results = await self.vector_repo.search(query_embedding)
        
        # 2. Slack search with keywords
        slack_results = await self.slack_client.search(error_log)
        
        # 3. Combine and rank
        combined = self._combine_results(vector_results, slack_results)
        
        return {
            "similar_incidents": vector_results,
            "slack_threads": slack_results,
            "relevance_scores": combined
        }
```
**Why it exists**: Centralized retrieval logic for RAG

### **app/services/embedder.py**
**Purpose**: Generate embeddings using NVIDIA API
**Contents**:
- Call NVIDIA embedding API
- Cache embeddings to avoid redundant API calls
- Batch processing for multiple texts
**Example**:
```python
class EmbedderService:
    def __init__(
        self,
        nvidia_client: NVIDIAEmbeddingClient,
        cache: CacheAdapter
    ):
        self.client = nvidia_client
        self.cache = cache
    
    async def embed(self, text: str) -> List[float]:
        # Check cache first
        cache_key = f"embedding:{hash(text)}"
        cached = self.cache.get(cache_key)
        if cached:
            return cached
        
        # Generate embedding
        embedding = await self.client.embed(text)
        
        # Cache result
        self.cache.set(cache_key, embedding, ttl=3600)
        
        return embedding
```
**Why it exists**: Wraps embedding API with caching

### **app/services/classifier.py**
**Purpose**: Failure classification logic
**Contents**:
- Parse error logs to extract failure type
- Map to known failure categories
- Extract relevant details (pod name, image, etc.)
**Example**:
```python
class ClassifierService:
    def classify_failure_type(self, error_log: str) -> str:
        # Rule-based classification before LLM
        if "ImagePullBackOff" in error_log:
            return "imagepullbackoff"
        elif "OOMKilled" in error_log:
            return "oomkilled"
        elif "CrashLoopBackOff" in error_log:
            return "crashloop"
        else:
            return "unknown"
```
**Why it exists**: Fast pre-classification before expensive LLM call

### **app/services/decision.py**
**Purpose**: Decide whether to auto-fix or escalate (Strategy Pattern)
**Contents**:
- Load appropriate strategy based on environment
- Check confidence threshold
- Check blast radius limits
- Apply business rules
**Example**:
```python
class DecisionService:
    def __init__(
        self,
        strategy_factory: StrategyFactory,
        rules_engine: RulesEngine
    ):
        self.strategy = strategy_factory.get_strategy()
        self.rules = rules_engine
    
    def should_auto_fix(self, analysis: AnalysisResult) -> bool:
        # 1. Check strategy (slack first, vector first, hybrid, etc.)
        strategy_decision = self.strategy.should_auto_fix(analysis)
        
        # 2. Check business rules
        rules_passed = self.rules.validate(analysis)
        
        # 3. Final decision
        return strategy_decision and rules_passed
```
**Why it exists**: Centralized decision logic with pluggable strategies

### **app/services/remediator.py**
**Purpose**: Execute remediation actions
**Contents**:
- Get appropriate remediation action from factory
- Run pre-remediation validation
- Execute action
- Run post-remediation validation
- Handle rollback if needed
**Example**:
```python
class RemediatorService:
    def __init__(
        self,
        action_factory: RemediationActionFactory,
        validator: ValidatorService,
        rollback: RollbackService
    ):
        self.factory = action_factory
        self.validator = validator
        self.rollback = rollback
    
    async def remediate(
        self,
        incident: Incident,
        analysis: AnalysisResult
    ) -> RemediationResult:
        # 1. Get appropriate action
        action = self.factory.create_action(analysis.category)
        
        # 2. Pre-validation
        pre_check = self.validator.validate_pre_remediation(incident)
        if not pre_check.passed:
            return RemediationResult(success=False, error="Pre-check failed")
        
        # 3. Take snapshot for rollback
        snapshot = await self.rollback.create_snapshot(incident)
        
        # 4. Execute action
        try:
            result = await action.execute(incident)
        except Exception as e:
            # 5. Rollback on failure
            await self.rollback.restore(snapshot)
            raise
        
        # 6. Post-validation
        post_check = self.validator.validate_post_remediation(incident)
        if not post_check.passed:
            await self.rollback.restore(snapshot)
            return RemediationResult(success=False, error="Post-check failed")
        
        return result
```
**Why it exists**: Orchestrates safe remediation execution

### **app/services/validator.py**
**Purpose**: Pre and post remediation validation
**Contents**:
- Pre-flight checks (is cluster healthy? is this safe to fix?)
- Post-fix health checks (did the fix work? did we break something?)
**Example**:
```python
class ValidatorService:
    def validate_pre_remediation(self, incident: Incident) -> ValidationResult:
        # Check blast radius (max fixes per hour)
        # Check if this action is blacklisted
        # Check if cluster/service is healthy
        pass
    
    def validate_post_remediation(self, incident: Incident) -> ValidationResult:
        # Check if incident is actually resolved
        # Check if any new failures appeared
        # Check service health metrics
        pass
```
**Why it exists**: Safety guardrails for autonomous actions

### **app/services/rollback.py**
**Purpose**: Rollback logic when remediation fails
**Contents**:
- Create snapshot of current state
- Restore previous state
- Detect when rollback is needed
**Example**:
```python
class RollbackService:
    async def create_snapshot(self, incident: Incident) -> Snapshot:
        # Take snapshot before remediation
        # For K8s: capture current replica count, image tag, etc.
        # For GitHub: capture workflow state
        pass
    
    async def restore(self, snapshot: Snapshot):
        # Restore to previous state
        pass
```
**Why it exists**: Allows safe recovery from bad fixes

### **app/services/feedback.py**
**Purpose**: Process human feedback on remediations
**Contents**:
- Record thumbs up/down on auto-fixes
- Update confidence calibration data
- Trigger model retraining if needed
**Example**:
```python
class FeedbackService:
    async def record_feedback(
        self,
        incident_id: str,
        helpful: bool,
        comment: Optional[str]
    ):
        # Update incident record
        # Add to training data
        # Recalculate success rate for this fix type
        pass
```
**Why it exists**: Learning loop for continuous improvement

### **app/services/learning.py**
**Purpose**: Model improvement and fine-tuning
**Contents**:
- Aggregate feedback data
- Trigger confidence recalibration
- Export training data for fine-tuning (future)
**Example**:
```python
class LearningService:
    async def recalibrate_confidence(self):
        # Query all resolved incidents
        # Calculate actual success rate per fix type
        # Update confidence thresholds
        pass
```
**Why it exists**: Continuous improvement of confidence scoring

---

## ðŸ“ app/services/confidence/ - Confidence Scoring Subsystem

### **app/services/confidence/scorer.py**
**Purpose**: Calculate confidence scores
**Contents**:
- Combine multiple confidence signals
- Weighted average of LLM confidence, similarity, historical success
**Example**:
```python
class ConfidenceScorer:
    def calculate(
        self,
        llm_confidence: float,
        similarity_score: float,
        historical_success_rate: float
    ) -> ConfidenceScore:
        # Weighted combination
        final_score = (
            0.4 * llm_confidence +
            0.3 * similarity_score +
            0.3 * historical_success_rate
        )
        
        return ConfidenceScore(
            llm_confidence=llm_confidence,
            similarity_score=similarity_score,
            historical_success_rate=historical_success_rate,
            final_score=final_score
        )
```
**Why it exists**: Centralized confidence calculation

### **app/services/confidence/calibrator.py**
**Purpose**: Calibrate confidence thresholds based on actual performance
**Contents**:
- Analyze historical data
- Adjust thresholds to hit target success rate
- A/B testing different thresholds
**Example**:
```python
class ConfidenceCalibrator:
    def calibrate(self, target_success_rate: float = 0.95):
        # Query all incidents with confidence > X
        # Calculate actual success rate
        # Adjust threshold until actual matches target
        pass
```
**Why it exists**: Ensures confidence scores are actually predictive

### **app/services/confidence/historical.py**
**Purpose**: Calculate historical success rates
**Contents**:
- Query past incidents of same type
- Calculate success rate
- Weight recent incidents more heavily
**Example**:
```python
class HistoricalAnalyzer:
    def calculate_success_rate(
        self,
        failure_type: str,
        remediation_type: str
    ) -> float:
        # Query incidents with same failure + remediation
        # Calculate: successes / total
        # Apply time decay (recent incidents weighted more)
        pass
```
**Why it exists**: Historical data is a strong confidence signal

---

*Due to length, I'll continue with the remaining sections in the next part. Would you like me to continue with the adapters, domain, utils, tests, and infrastructure sections?*
