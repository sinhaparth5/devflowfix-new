# ============================================================================
# DevFlowFix Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control!
# ============================================================================

# ============================================================================
# Application Settings
# ============================================================================

# Environment: dev, staging, prod
ENVIRONMENT=dev

# Application version
VERSION=0.1.0

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable debug mode (verbose logging, detailed errors)
DEBUG=false

# Log format: json or console
LOG_FORMAT=console

# Enable logging to file
LOG_TO_FILE=true

# Log file path (when LOG_TO_FILE=true)
LOG_FILE_PATH=/var/log/devflowfix/app.log


# ============================================================================
# Database Settings (PostgreSQL)
# ============================================================================

# PostgreSQL connection URL
# Format: postgresql://username:password@host:port/database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/vector_db

# Connection pool settings
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_POOL_RECYCLE=3600


# ============================================================================
# NVIDIA API Settings (for LLM and Embeddings)
# ============================================================================

# NVIDIA NGC API key (get from https://build.nvidia.com)
NVIDIA_API_KEY=nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# NVIDIA API base URL (usually don't need to change)
NVIDIA_API_BASE_URL=https://api.nvcf.nvidia.com/v2/nvcf/pexec/functions

# LLM model for incident analysis
# Options: meta/llama-3.1-8b-instruct, meta/llama-3.1-70b-instruct
NVIDIA_LLM_MODEL=meta/llama-3.1-8b-instruct

# Embedding model for vector generation
# Options: nvidia/nv-embed-v1, nvidia/nv-embedqa-e5-v5
NVIDIA_EMBEDDING_MODEL=nvidia/nv-embed-v1

# API request timeout (seconds)
NVIDIA_API_TIMEOUT=30

# Maximum retry attempts for failed API calls
NVIDIA_MAX_RETRIES=3


# ============================================================================
# GitHub Integration
# ============================================================================

# GitHub Personal Access Token or App Installation Token
# Required scopes: repo, workflow, admin:repo_hook
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# GitHub webhook secret for signature verification
# Set this in your GitHub webhook configuration
GITHUB_WEBHOOK_SECRET=your-webhook-secret-here

# GitHub API base URL (usually don't need to change)
GITHUB_API_BASE_URL=https://api.github.com


# ============================================================================
# Slack Integration
# ============================================================================

# Slack Bot Token (starts with xoxb-)
# Get from: https://api.slack.com/apps -> OAuth & Permissions
SLACK_TOKEN=xoxb-xxxxxxxxxxxxx-xxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxx

# Slack Signing Secret for request verification
# Get from: https://api.slack.com/apps -> Basic Information
SLACK_SIGNING_SECRET=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Slack channel for incident notifications
SLACK_INCIDENTS_CHANNEL=#incidents

# Slack channel for approval requests
SLACK_APPROVALS_CHANNEL=#devflowfix-approvals


# ============================================================================
# ArgoCD Integration (Optional)
# ============================================================================

# ArgoCD server URL (without https://)
ARGOCD_SERVER=argocd.example.com

# ArgoCD API token
# Get from: argocd account generate-token
ARGOCD_TOKEN=argocd.token.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Skip TLS verification (development only!)
ARGOCD_INSECURE=false


# ============================================================================
# Kubernetes Integration
# ============================================================================

# Path to kubeconfig file (leave empty to use default ~/.kube/config)
KUBECONFIG_PATH=

# Default Kubernetes namespace
KUBERNETES_NAMESPACE=default


# ============================================================================
# PagerDuty Integration (Optional)
# ============================================================================

# PagerDuty API key
# Get from: https://support.pagerduty.com/docs/api-access-keys
PAGERDUTY_API_KEY=

# PagerDuty service ID
PAGERDUTY_SERVICE_ID=


# ============================================================================
# AWS Settings
# ============================================================================

# AWS region
AWS_REGION=us-east-1

# AWS account ID
AWS_ACCOUNT_ID=123456789012

# AWS credentials are typically loaded from ~/.aws/credentials
# or IAM roles when running on EC2/ECS/Lambda


# ============================================================================
# Backblaze B2 Storage Settings
# ============================================================================

# Backblaze B2 Key ID (similar to AWS Access Key)
# Get from: https://secure.backblaze.com/app_keys.htm
BACKBLAZE_KEY_ID=your_backblaze_key_id

# Backblaze B2 Application Key (similar to AWS Secret Key)
# Get from: https://secure.backblaze.com/app_keys.htm
BACKBLAZE_APPLICATION_KEY=your_backblaze_application_key

# Backblaze B2 Bucket Name
# The bucket must already be created and configured for public access
BACKBLAZE_BUCKET_NAME=your_bucket_name

# Backblaze B2 Endpoint URL
# Format: https://s3.<region>.backblazeb2.com
# Example: https://s3.us-west-001.backblazeb2.com
BACKBLAZE_ENDPOINT_URL=https://s3.us-west-001.backblazeb2.com

# Backblaze B2 Region
# Common regions: us-west-001, us-west-002, us-west-004, eu-central-003
BACKBLAZE_REGION=us-west-001


# ============================================================================
# Redis Settings (for caching, RAG, and rate limiting)
# ============================================================================

# Redis connection URL
#
# Local Redis:
#   REDIS_URL=redis://localhost:6379/0
#
# Redis Cloud (cloud.redis.io):
#   Get your endpoint from: https://cloud.redis.io > Your Database > Configuration
#   Format: redis://:PASSWORD@HOST:PORT/0
#   Example: redis://:Abc123XyZ@redis-12345.c1.us-east-1-2.ec2.cloud.redislabs.com:12345/0
#
# Railway/Heroku/other cloud:
#   Use the REDIS_URL provided by your platform
#
REDIS_URL=redis://localhost:6379/0

# Redis password (optional - already included in REDIS_URL for Redis Cloud)
# Only needed if using password-protected local Redis
REDIS_PASSWORD=

# Time-to-live for cached items (seconds)
# Default: 3600 (1 hour)
# Adjust based on your needs:
#   - LLM responses: 3600-7200 (1-2 hours)
#   - RAG results: 1800-3600 (30-60 minutes)
#   - Rate limit counters: 60-300 (1-5 minutes)
REDIS_TTL=3600

# Redis connection pool settings
REDIS_MAX_CONNECTIONS=10
REDIS_SOCKET_TIMEOUT=5

# ============================================================================
# Redis Cloud Setup Guide
# ============================================================================
#
# 1. Sign up at https://cloud.redis.io (free 30MB tier available)
# 2. Create a new database:
#    - Name: devflowfix-cache
#    - Cloud: AWS (recommended)
#    - Region: Same as your app (e.g., us-east-1)
#    - Type: Redis Stack (includes JSON, Search modules)
# 3. Get connection details from Configuration tab:
#    - Endpoint: redis-xxxxx.c1.region.ec2.cloud.redislabs.com:12345
#    - Password: your-password-here
# 4. Build connection URL:
#    REDIS_URL=redis://:YOUR_PASSWORD@YOUR_ENDPOINT/0
# 5. Test connection: python test_redis.py
#
# For detailed setup instructions, see: REDIS_CLOUD_SETUP.md
#
# ============================================================================


# ============================================================================
# Confidence & Safety Settings
# ============================================================================

# Minimum confidence threshold for any auto-fix consideration
MIN_CONFIDENCE_THRESHOLD=0.70

# Threshold for high confidence classification
HIGH_CONFIDENCE_THRESHOLD=0.85

# Required confidence for production auto-fix
PRODUCTION_CONFIDENCE_THRESHOLD=0.95


# ============================================================================
# Blast Radius Settings
# ============================================================================

# Maximum auto-fixes per hour per service
MAX_FIXES_PER_HOUR=10

# Maximum auto-fixes per day per service
MAX_FIXES_PER_DAY=50

# Maximum concurrent remediation executions
MAX_CONCURRENT_REMEDIATIONS=5


# ============================================================================
# Embeddings Settings
# ============================================================================

# Vector embedding dimension (must match model)
# NV-Embed-V1: 768, OpenAI ada-002: 1536
EMBEDDING_DIMENSION=768


# ============================================================================
# Remediation Settings
# ============================================================================

# Remediation execution timeout (seconds)
REMEDIATION_TIMEOUT_SECONDS=300

# Maximum retry attempts for failed remediation
REMEDIATION_MAX_RETRIES=3

# Enable automatic rollback on failure
ENABLE_ROLLBACK=true

# Time-to-live for rollback snapshots (hours)
ROLLBACK_SNAPSHOT_TTL_HOURS=24


# ============================================================================
# Approval Settings
# ============================================================================

# Approval request timeout (minutes)
APPROVAL_TIMEOUT_MINUTES=30

# Always require approval for production remediations
REQUIRE_APPROVAL_FOR_PRODUCTION=true


# ============================================================================
# RAG (Retrieval-Augmented Generation) Settings
# ============================================================================

# Number of similar incidents to retrieve
RAG_TOP_K=5

# Minimum similarity score for retrieval
RAG_SIMILARITY_THRESHOLD=0.70

# Maximum context length for RAG (tokens)
RAG_MAX_CONTEXT_LENGTH=4000


# ============================================================================
# CORS Settings
# ============================================================================

# Allowed CORS origins (comma-separated)
# Use "*" for development, specific domains for production
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Allow credentials in CORS requests
CORS_ALLOW_CREDENTIALS=true


# ============================================================================
# Rate Limiting Settings
# ============================================================================

# Enable rate limiting
RATE_LIMIT_ENABLED=true

# Requests per minute per client
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Requests per hour per client
RATE_LIMIT_REQUESTS_PER_HOUR=1000


# ============================================================================
# Feature Flags
# ============================================================================

# Enable RAG retrieval from Slack conversations
ENABLE_SLACK_RAG=true

# Enable automatic remediation execution
ENABLE_AUTO_FIX=true

# Enable metrics collection and reporting
ENABLE_METRICS=true

# Enable distributed tracing (AWS X-Ray)
ENABLE_TRACING=false

# Enable learning from feedback
ENABLE_LEARNING=true

# Enable webhook endpoints
ENABLE_WEBHOOKS=true


# ============================================================================
# Security Settings
# ============================================================================

# Secret key for signing tokens
# IMPORTANT: Generate a secure random string for production!
# Use: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=change-me-in-production-use-secrets-manager

# JWT signing algorithm
JWT_ALGORITHM=HS256

# JWT token expiration (minutes)
JWT_EXPIRATION_MINUTES=60

# Encryption key for sensitive data (GitHub tokens, secrets, etc.)
# IMPORTANT: Generate using: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# This key is used to encrypt GitHub tokens and other sensitive data at rest
DEVFLOWFIX_ENCRYPTION_KEY=


# ============================================================================
# Observability Settings
# ============================================================================

# Interval for exporting metrics (seconds)
METRICS_EXPORT_INTERVAL_SECONDS=60


# ============================================================================
# Development/Testing Settings
# ============================================================================

# These settings are useful for development and testing

# Run migrations automatically on startup
# AUTO_MIGRATE=false

# Seed database with test data
# SEED_TEST_DATA=false

# Enable SQL query logging
# SQL_ECHO=false


# ============================================================================
# Production Recommendations
# ============================================================================
#
# For production deployments:
#
# 1. Use AWS Secrets Manager for sensitive values:
#    NVIDIA_API_KEY=arn:aws:secretsmanager:region:account:secret:name
#    GITHUB_TOKEN=arn:aws:secretsmanager:region:account:secret:name
#    SLACK_TOKEN=arn:aws:secretsmanager:region:account:secret:name
#
# 2. Set strong SECRET_KEY:
#    SECRET_KEY=$(python -c "import secrets; print(secrets.token_urlsafe(32))")
#
# 3. Use specific CORS origins:
#    CORS_ORIGINS=https://yourdomain.com,https://app.yourdomain.com
#
# 4. Enable Redis for better performance:
#    REDIS_URL=redis://your-redis-cluster:6379/0
#
# 5. Set appropriate confidence thresholds:
#    PRODUCTION_CONFIDENCE_THRESHOLD=0.95
#    REQUIRE_APPROVAL_FOR_PRODUCTION=true
#
# 6. Configure proper logging:
#    LOG_LEVEL=INFO
#    LOG_FORMAT=json
#    LOG_TO_FILE=true
#
# 7. Enable tracing in production:
#    ENABLE_TRACING=true
#
# ============================================================================
